{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Neural Network-Based Flow Field Compression — Offline Training & Evaluation\n- **Base Model**: 4 → 64 → 64 → 32 → 4 (6,692 parameters)\n- **Large Model**: 4 → 128 → 128 → 64 → 4 (25,476 parameters)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\"\"\"Unified Training Utilities for Neural Network-Based Flow Field Compression\"\"\"\n\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nimport pyarrow.csv as pv\nfrom torcheval.metrics import PeakSignalNoiseRatio\nfrom torchmetrics.image import StructuralSimilarityIndexMeasure\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport json\n\n\nclass FlowFieldDataset(Dataset):\n    \"\"\"Spatio-temporal flow field dataset with min-max normalization to [0, 1].\"\"\"\n\n    def __init__(self, filepath):\n        print(f\"[Data] Loading dataset from {filepath}\")\n        read_options = pv.ReadOptions(\n            column_names=['x', 'y', 'z', 't', 'Vx', 'Vy', 'Pressure', 'TKE']\n        )\n        table = pv.read_csv(filepath, read_options=read_options)\n        data = table.to_pandas().values\n        self.inputs = data[:, :4].astype(np.float32)\n        self.targets = data[:, 4:].astype(np.float32)\n        print(\"[Data] Applying min-max normalization to [0, 1] range\")\n        self.input_min = self.inputs.min(axis=0)\n        self.input_max = self.inputs.max(axis=0)\n        self.input_range = self.input_max - self.input_min\n        self.input_range[self.input_range == 0] = 1.0\n        self.inputs = (self.inputs - self.input_min) / self.input_range\n        self.target_min = self.targets.min(axis=0)\n        self.target_max = self.targets.max(axis=0)\n        self.target_range = self.target_max - self.target_min\n        self.target_range[self.target_range == 0] = 1.0\n        self.targets = (self.targets - self.target_min) / self.target_range\n        print(f\"[Data] Loaded {len(self):,} samples | Input: {self.inputs.shape} | Target: {self.targets.shape}\")\n\n    def __len__(self):\n        return len(self.inputs)\n\n    def __getitem__(self, idx):\n        return torch.from_numpy(self.inputs[idx]), torch.from_numpy(self.targets[idx])\n\n    def denormalize_input(self, normalized):\n        if isinstance(normalized, torch.Tensor):\n            normalized = normalized.cpu().numpy()\n        return normalized * self.input_range + self.input_min\n\n    def denormalize_target(self, normalized):\n        if isinstance(normalized, torch.Tensor):\n            normalized = normalized.cpu().numpy()\n        return normalized * self.target_range + self.target_min\n\n\nclass BaseCompressor(nn.Module):\n    \"\"\"Base compression network: 4 -> 64 -> 64 -> 32 -> 4\"\"\"\n\n    def __init__(self):\n        super(BaseCompressor, self).__init__()\n        self.model = nn.Sequential(\n            nn.Linear(4, 64),\n            nn.ReLU(),\n            nn.Linear(64, 64),\n            nn.ReLU(),\n            nn.Linear(64, 32),\n            nn.ReLU(),\n            nn.Linear(32, 4)\n        )\n\n    def forward(self, x):\n        return self.model(x)\n\n\nclass LargeCompressor(nn.Module):\n    \"\"\"Large compression network: 4 -> 128 -> 128 -> 64 -> 4\"\"\"\n\n    def __init__(self):\n        super(LargeCompressor, self).__init__()\n        self.model = nn.Sequential(\n            nn.Linear(4, 128),\n            nn.ReLU(),\n            nn.Linear(128, 128),\n            nn.ReLU(),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Linear(64, 4)\n        )\n\n    def forward(self, x):\n        return self.model(x)\n\n\ndef compute_psnr_ssim(predictions, targets, device):\n    \"\"\"Compute PSNR and SSIM for regression data using per-point comparison (kernel_size=1).\"\"\"\n    predictions = predictions.to(device)\n    targets = targets.to(device)\n\n    psnr_metric = PeakSignalNoiseRatio().to(device)\n    psnr_metric.update(predictions, targets)\n    psnr = psnr_metric.compute().item()\n\n    pred_ssim = predictions.view(-1, 1, 1, predictions.shape[1])\n    target_ssim = targets.view(-1, 1, 1, targets.shape[1])\n    pred_ssim = pred_ssim.permute(1, 2, 0, 3)\n    target_ssim = target_ssim.permute(1, 2, 0, 3)\n\n    ssim_metric = StructuralSimilarityIndexMeasure(\n        gaussian_kernel=False, kernel_size=1\n    ).to(device)\n    ssim_metric.update(pred_ssim, target_ssim)\n    ssim = ssim_metric.compute().item()\n\n    return psnr, ssim\n\n\ndef compute_relative_error(predictions, targets):\n    \"\"\"Compute relative L2 norm error as a percentage.\"\"\"\n    target_norm = torch.norm(targets)\n    error = torch.norm(predictions - targets)\n    return (error / target_norm * 100).item()\n\n\ndef train_model(model, train_loader, dataset, device, epochs, model_name, output_dir):\n    \"\"\"Train a compression model and save weights, normalization parameters, and metrics.\"\"\"\n    os.makedirs(output_dir, exist_ok=True)\n    criterion = nn.MSELoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    metrics = {'loss': [], 'psnr': [], 'ssim': [], 'relative_error': [], 'time_per_epoch': []}\n    total_params = sum(p.numel() for p in model.parameters())\n    print(f\"\\n[Train] Model: {model_name}\")\n    print(f\"[Train] Samples: {len(dataset):,} | Epochs: {epochs} | Device: {device}\")\n    print(f\"[Train] Parameters: {total_params:,} | Size: {total_params * 4 / 1024:.2f} KB\\n\")\n    for epoch in range(epochs):\n        epoch_start = time.time()\n        model.train()\n        epoch_loss = 0.0\n        all_predictions = []\n        all_targets = []\n        for batch_idx, (inputs, targets) in enumerate(train_loader):\n            inputs, targets = inputs.to(device), targets.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n            epoch_loss += loss.item()\n            all_predictions.append(outputs.detach())\n            all_targets.append(targets)\n        epoch_loss /= len(train_loader)\n        metrics['loss'].append(epoch_loss)\n        all_predictions = torch.cat(all_predictions, dim=0)\n        all_targets = torch.cat(all_targets, dim=0)\n        psnr, ssim = compute_psnr_ssim(all_predictions, all_targets, device)\n        rel_error = compute_relative_error(all_predictions, all_targets)\n        metrics['psnr'].append(psnr)\n        metrics['ssim'].append(ssim)\n        metrics['relative_error'].append(rel_error)\n        epoch_time = time.time() - epoch_start\n        metrics['time_per_epoch'].append(epoch_time)\n        if (epoch + 1) % 10 == 0 or epoch == 0:\n            print(f\"  Epoch {epoch+1:>3}/{epochs}: Loss={epoch_loss:.6f}, \"\n                  f\"PSNR={psnr:.2f} dB, SSIM={ssim:.4f}, \"\n                  f\"Rel. Error={rel_error:.2f}%, Time={epoch_time:.2f}s\")\n    model_path = os.path.join(output_dir, f'{model_name}_minmax.pth')\n    torch.save(model.state_dict(), model_path)\n    print(f\"\\n[Train] Model saved: {model_path}\")\n    norm_params = {\n        'input_min': dataset.input_min.tolist(),\n        'input_max': dataset.input_max.tolist(),\n        'input_range': dataset.input_range.tolist(),\n        'target_min': dataset.target_min.tolist(),\n        'target_max': dataset.target_max.tolist(),\n        'target_range': dataset.target_range.tolist()\n    }\n    norm_path = os.path.join(output_dir, f'{model_name}_normalization.json')\n    with open(norm_path, 'w') as f:\n        json.dump(norm_params, f, indent=2)\n    print(f\"[Train] Normalization parameters saved: {norm_path}\")\n    print(f\"\\n[Train] Training completed for {model_name}\")\n    print(f\"  Final Loss:           {metrics['loss'][-1]:.6f}\")\n    print(f\"  Final PSNR:           {metrics['psnr'][-1]:.2f} dB\")\n    print(f\"  Final SSIM:           {metrics['ssim'][-1]:.4f}\")\n    print(f\"  Final Relative Error: {metrics['relative_error'][-1]:.2f}%\")\n    print(f\"  PSNR Improvement:     {metrics['psnr'][0]:.2f} \\u2192 {metrics['psnr'][-1]:.2f} dB \"\n          f\"({metrics['psnr'][-1]-metrics['psnr'][0]:+.2f} dB)\\n\")\n    return metrics\n\n\ndef export_metrics_csv(metrics, output_path):\n    \"\"\"Export training metrics history to CSV.\"\"\"\n    df = pd.DataFrame(metrics)\n    df['epoch'] = range(1, len(df) + 1)\n    df = df[['epoch', 'loss', 'psnr', 'ssim', 'relative_error', 'time_per_epoch']]\n    df.to_csv(output_path, index=False)\n    print(f\"[Export] Metrics saved: {output_path}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "DATA_FILE = \"/kaggle/input/ml-test-loader-original-data-csv/ML_test_loader_original_data.csv\"\nEPOCHS = 150\nBATCH_SIZE = 512\nTIMESTEP = 0.0396\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"[Config] Device: {device}\")\n\ndataset = FlowFieldDataset(DATA_FILE)\ntrain_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Base Model (64-64-32) — Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "BASE_OUTPUT_DIR = \"/kaggle/working/results/base_model_offline\"\n\nbase_model = BaseCompressor().to(device)\n\nbase_metrics = train_model(\n    model=base_model,\n    train_loader=train_loader,\n    dataset=dataset,\n    device=device,\n    epochs=EPOCHS,\n    model_name='base_model',\n    output_dir=BASE_OUTPUT_DIR\n)\n\nexport_metrics_csv(base_metrics, f\"{BASE_OUTPUT_DIR}/base_model_metrics.csv\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\nepochs_range = range(1, len(base_metrics['loss']) + 1)\n\naxes[0, 0].plot(epochs_range, base_metrics['loss'], 'b-', linewidth=2)\naxes[0, 0].set_xlabel('Epoch')\naxes[0, 0].set_ylabel('MSE Loss')\naxes[0, 0].set_title('Training Loss (Normalized)')\naxes[0, 0].grid(True, alpha=0.3)\n\naxes[0, 1].plot(epochs_range, base_metrics['psnr'], 'g-', linewidth=2)\naxes[0, 1].set_xlabel('Epoch')\naxes[0, 1].set_ylabel('PSNR (dB)')\naxes[0, 1].set_title('Peak Signal-to-Noise Ratio')\naxes[0, 1].grid(True, alpha=0.3)\n\naxes[1, 0].plot(epochs_range, base_metrics['ssim'], 'purple', linewidth=2)\naxes[1, 0].set_xlabel('Epoch')\naxes[1, 0].set_ylabel('SSIM')\naxes[1, 0].set_title('Structural Similarity Index')\naxes[1, 0].grid(True, alpha=0.3)\naxes[1, 0].set_ylim([0, 1.05])\n\naxes[1, 1].plot(epochs_range, base_metrics['relative_error'], 'r-', linewidth=2)\naxes[1, 1].set_xlabel('Epoch')\naxes[1, 1].set_ylabel('Relative Error (%)')\naxes[1, 1].set_title('Reconstruction Error')\naxes[1, 1].grid(True, alpha=0.3)\n\nplt.suptitle('Base Model (64-64-32) — Offline Training', fontsize=14, fontweight='bold')\nplt.tight_layout()\nplt.savefig(f\"{BASE_OUTPUT_DIR}/base_model_training_progress.png\", dpi=300, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1.1 Base Model — Evaluation & Visualization"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "BASE_VIZ_DIR = \"/kaggle/working/results/base_model_offline_viz\"\nos.makedirs(BASE_VIZ_DIR, exist_ok=True)\n\nbase_model.load_state_dict(torch.load(f\"{BASE_OUTPUT_DIR}/base_model_minmax.pth\", map_location=device))\nbase_model.eval()\n\nprint(f\"[Eval] Base model: {sum(p.numel() for p in base_model.parameters()):,} parameters\")\n\nall_inputs = torch.from_numpy(dataset.inputs).to(device)\nwith torch.no_grad():\n    base_predictions = base_model(all_inputs).cpu()\n\nall_targets = torch.from_numpy(dataset.targets)\n\nbase_psnr, base_ssim = compute_psnr_ssim(base_predictions, all_targets, device)\nprint(f\"[Eval] PSNR: {base_psnr:.2f} dB | SSIM: {base_ssim:.4f}\")\n\nbase_pred_denorm = dataset.denormalize_target(base_predictions.numpy())\ntargets_denorm = dataset.denormalize_target(all_targets.numpy())\ncoords_denorm = dataset.denormalize_input(dataset.inputs)\n\ntimestep_mask = np.abs(coords_denorm[:, 3] - TIMESTEP) < 1e-6\nx = coords_denorm[timestep_mask, 0]\ny = coords_denorm[timestep_mask, 1]\nbase_pred_t = base_pred_denorm[timestep_mask]\ntarget_t = targets_denorm[timestep_mask]\nbase_errors_t = np.abs(target_t - base_pred_t)\n\nprint(f\"[Eval] Visualizing {len(x):,} points at timestep {TIMESTEP}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "feature_names = ['Vx', 'Vy', 'Pressure', 'TKE']\nfeature_indices = [0, 1, 2, 3]\n\nfig, axes = plt.subplots(4, 3, figsize=(18, 20))\n\nfor row, (idx, name) in enumerate(zip(feature_indices, feature_names)):\n    original = target_t[:, idx]\n    predicted = base_pred_t[:, idx]\n    error = base_errors_t[:, idx]\n\n    sc1 = axes[row, 0].scatter(x, y, c=original, cmap='jet', s=0.5, alpha=0.8)\n    axes[row, 0].set_title(f'Original: {name}')\n    axes[row, 0].set_aspect('equal')\n    axes[row, 0].grid(True, alpha=0.3)\n    plt.colorbar(sc1, ax=axes[row, 0])\n\n    sc2 = axes[row, 1].scatter(x, y, c=predicted, cmap='jet', s=0.5, alpha=0.8)\n    axes[row, 1].set_title(f'Predicted: {name}')\n    axes[row, 1].set_aspect('equal')\n    axes[row, 1].grid(True, alpha=0.3)\n    plt.colorbar(sc2, ax=axes[row, 1])\n\n    sc3 = axes[row, 2].scatter(x, y, c=error, cmap='hot', s=0.5, alpha=0.8)\n    axes[row, 2].set_title(f'Absolute Error: {name}')\n    axes[row, 2].set_aspect('equal')\n    axes[row, 2].grid(True, alpha=0.3)\n    plt.colorbar(sc3, ax=axes[row, 2])\n\nplt.suptitle(f'Base Model (64-64-32) — PSNR: {base_psnr:.2f} dB | Timestep: {TIMESTEP}',\n             fontsize=14, fontweight='bold', y=0.995)\nplt.tight_layout()\nplt.savefig(f\"{BASE_VIZ_DIR}/base_flow_visualization.png\", dpi=150, bbox_inches='tight')\nplt.show()\n\nbase_eval_metrics = {\n    'model': 'base_model_minmax.pth',\n    'architecture': '4-64-64-32-4',\n    'parameters': sum(p.numel() for p in base_model.parameters()),\n    'psnr_db': float(base_psnr),\n    'ssim': float(base_ssim)\n}\n\nwith open(f\"{BASE_VIZ_DIR}/evaluation_metrics.json\", 'w') as f:\n    json.dump(base_eval_metrics, f, indent=2)\n\nprint(\"[Eval] Base model evaluation completed\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Large Model (128-128-64) — Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "LARGE_OUTPUT_DIR = \"/kaggle/working/results/large_model_offline\"\n\nlarge_model = LargeCompressor().to(device)\n\nlarge_metrics = train_model(\n    model=large_model,\n    train_loader=train_loader,\n    dataset=dataset,\n    device=device,\n    epochs=EPOCHS,\n    model_name='large_model',\n    output_dir=LARGE_OUTPUT_DIR\n)\n\nexport_metrics_csv(large_metrics, f\"{LARGE_OUTPUT_DIR}/large_model_metrics.csv\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\nepochs_range = range(1, len(large_metrics['loss']) + 1)\n\naxes[0, 0].plot(epochs_range, large_metrics['loss'], 'b-', linewidth=2)\naxes[0, 0].set_xlabel('Epoch')\naxes[0, 0].set_ylabel('MSE Loss')\naxes[0, 0].set_title('Training Loss (Normalized)')\naxes[0, 0].grid(True, alpha=0.3)\n\naxes[0, 1].plot(epochs_range, large_metrics['psnr'], 'g-', linewidth=2)\naxes[0, 1].set_xlabel('Epoch')\naxes[0, 1].set_ylabel('PSNR (dB)')\naxes[0, 1].set_title('Peak Signal-to-Noise Ratio')\naxes[0, 1].grid(True, alpha=0.3)\n\naxes[1, 0].plot(epochs_range, large_metrics['ssim'], 'purple', linewidth=2)\naxes[1, 0].set_xlabel('Epoch')\naxes[1, 0].set_ylabel('SSIM')\naxes[1, 0].set_title('Structural Similarity Index')\naxes[1, 0].grid(True, alpha=0.3)\naxes[1, 0].set_ylim([0, 1.05])\n\naxes[1, 1].plot(epochs_range, large_metrics['relative_error'], 'r-', linewidth=2)\naxes[1, 1].set_xlabel('Epoch')\naxes[1, 1].set_ylabel('Relative Error (%)')\naxes[1, 1].set_title('Reconstruction Error')\naxes[1, 1].grid(True, alpha=0.3)\n\nplt.suptitle('Large Model (128-128-64) — Offline Training', fontsize=14, fontweight='bold')\nplt.tight_layout()\nplt.savefig(f\"{LARGE_OUTPUT_DIR}/large_model_training_progress.png\", dpi=300, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2.1 Large Model — Evaluation & Visualization"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "LARGE_VIZ_DIR = \"/kaggle/working/results/large_model_offline_viz\"\nos.makedirs(LARGE_VIZ_DIR, exist_ok=True)\n\nlarge_model.load_state_dict(torch.load(f\"{LARGE_OUTPUT_DIR}/large_model_minmax.pth\", map_location=device))\nlarge_model.eval()\n\nprint(f\"[Eval] Large model: {sum(p.numel() for p in large_model.parameters()):,} parameters\")\n\nwith torch.no_grad():\n    large_predictions = large_model(all_inputs).cpu()\n\nlarge_psnr, large_ssim = compute_psnr_ssim(large_predictions, all_targets, device)\nprint(f\"[Eval] PSNR: {large_psnr:.2f} dB | SSIM: {large_ssim:.4f}\")\n\nlarge_pred_denorm = dataset.denormalize_target(large_predictions.numpy())\n\nlarge_pred_t = large_pred_denorm[timestep_mask]\nlarge_errors_t = np.abs(target_t - large_pred_t)\n\nprint(f\"[Eval] Visualizing {len(x):,} points at timestep {TIMESTEP}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "fig, axes = plt.subplots(4, 3, figsize=(18, 20))\n\nfor row, (idx, name) in enumerate(zip(feature_indices, feature_names)):\n    original = target_t[:, idx]\n    predicted = large_pred_t[:, idx]\n    error = large_errors_t[:, idx]\n\n    sc1 = axes[row, 0].scatter(x, y, c=original, cmap='jet', s=0.5, alpha=0.8)\n    axes[row, 0].set_title(f'Original: {name}')\n    axes[row, 0].set_aspect('equal')\n    axes[row, 0].grid(True, alpha=0.3)\n    plt.colorbar(sc1, ax=axes[row, 0])\n\n    sc2 = axes[row, 1].scatter(x, y, c=predicted, cmap='jet', s=0.5, alpha=0.8)\n    axes[row, 1].set_title(f'Predicted: {name}')\n    axes[row, 1].set_aspect('equal')\n    axes[row, 1].grid(True, alpha=0.3)\n    plt.colorbar(sc2, ax=axes[row, 1])\n\n    sc3 = axes[row, 2].scatter(x, y, c=error, cmap='hot', s=0.5, alpha=0.8)\n    axes[row, 2].set_title(f'Absolute Error: {name}')\n    axes[row, 2].set_aspect('equal')\n    axes[row, 2].grid(True, alpha=0.3)\n    plt.colorbar(sc3, ax=axes[row, 2])\n\nplt.suptitle(f'Large Model (128-128-64) — PSNR: {large_psnr:.2f} dB | Timestep: {TIMESTEP}',\n             fontsize=14, fontweight='bold', y=0.995)\nplt.tight_layout()\nplt.savefig(f\"{LARGE_VIZ_DIR}/large_flow_visualization.png\", dpi=150, bbox_inches='tight')\nplt.show()\n\nlarge_eval_metrics = {\n    'model': 'large_model_minmax.pth',\n    'architecture': '4-128-128-64-4',\n    'parameters': sum(p.numel() for p in large_model.parameters()),\n    'psnr_db': float(large_psnr),\n    'ssim': float(large_ssim)\n}\n\nwith open(f\"{LARGE_VIZ_DIR}/evaluation_metrics.json\", 'w') as f:\n    json.dump(large_eval_metrics, f, indent=2)\n\nprint(\"[Eval] Large model evaluation completed\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 65)\nprint(\"MODEL COMPARISON SUMMARY\")\nprint(\"=\" * 65)\nprint(f\"{'Metric':<25} {'Base (64-64-32)':>18} {'Large (128-128-64)':>20}\")\nprint(\"-\" * 65)\nprint(f\"{'Parameters':<25} {sum(p.numel() for p in base_model.parameters()):>18,} {sum(p.numel() for p in large_model.parameters()):>20,}\")\nprint(f\"{'Model Size (KB)':<25} {sum(p.numel() for p in base_model.parameters()) * 4 / 1024:>18.2f} {sum(p.numel() for p in large_model.parameters()) * 4 / 1024:>20.2f}\")\nprint(f\"{'Final Train Loss':<25} {base_metrics['loss'][-1]:>18.6f} {large_metrics['loss'][-1]:>20.6f}\")\nprint(f\"{'Final Train PSNR (dB)':<25} {base_metrics['psnr'][-1]:>18.2f} {large_metrics['psnr'][-1]:>20.2f}\")\nprint(f\"{'Final Train SSIM':<25} {base_metrics['ssim'][-1]:>18.4f} {large_metrics['ssim'][-1]:>20.4f}\")\nprint(f\"{'Final Rel. Error (%)':<25} {base_metrics['relative_error'][-1]:>18.2f} {large_metrics['relative_error'][-1]:>20.2f}\")\nprint(f\"{'Eval PSNR (dB)':<25} {base_psnr:>18.2f} {large_psnr:>20.2f}\")\nprint(f\"{'Eval SSIM':<25} {base_ssim:>18.4f} {large_ssim:>20.4f}\")\nprint(\"=\" * 65)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}