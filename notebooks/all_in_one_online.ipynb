{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network-Based Flow Field Compression — Online Training & Evaluation\n",
    "Streaming in-situ training with temporal windows.\n",
    "- **Base Model**: 4 → 64 → 64 → 32 → 4 (6,692 parameters)\n",
    "- **Large Model**: 4 → 128 → 128 → 64 → 4 (25,668 parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Unified Utilities for Neural Network-Based Flow Field Compression\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pyarrow.csv as pv\n",
    "from torcheval.metrics import PeakSignalNoiseRatio\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "class FlowFieldDataset(Dataset):\n",
    "    \"\"\"Spatio-temporal flow field dataset with min-max normalization to [0, 1].\"\"\"\n",
    "\n",
    "    def __init__(self, filepath):\n",
    "        print(f\"[Data] Loading dataset from {filepath}\")\n",
    "        read_options = pv.ReadOptions(\n",
    "            column_names=['x', 'y', 'z', 't', 'Vx', 'Vy', 'Pressure', 'TKE']\n",
    "        )\n",
    "        table = pv.read_csv(filepath, read_options=read_options)\n",
    "        data = table.to_pandas().values\n",
    "        self.inputs = data[:, :4].astype(np.float32)\n",
    "        self.targets = data[:, 4:].astype(np.float32)\n",
    "        print(\"[Data] Applying min-max normalization to [0, 1] range\")\n",
    "        self.input_min = self.inputs.min(axis=0)\n",
    "        self.input_max = self.inputs.max(axis=0)\n",
    "        self.input_range = self.input_max - self.input_min\n",
    "        self.input_range[self.input_range == 0] = 1.0\n",
    "        self.inputs = (self.inputs - self.input_min) / self.input_range\n",
    "        self.target_min = self.targets.min(axis=0)\n",
    "        self.target_max = self.targets.max(axis=0)\n",
    "        self.target_range = self.target_max - self.target_min\n",
    "        self.target_range[self.target_range == 0] = 1.0\n",
    "        self.targets = (self.targets - self.target_min) / self.target_range\n",
    "        print(f\"[Data] Loaded {len(self):,} samples | Input: {self.inputs.shape} | Target: {self.targets.shape}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.inputs[idx]), torch.from_numpy(self.targets[idx])\n",
    "\n",
    "    def denormalize_input(self, normalized):\n",
    "        if isinstance(normalized, torch.Tensor):\n",
    "            normalized = normalized.cpu().numpy()\n",
    "        return normalized * self.input_range + self.input_min\n",
    "\n",
    "    def denormalize_target(self, normalized):\n",
    "        if isinstance(normalized, torch.Tensor):\n",
    "            normalized = normalized.cpu().numpy()\n",
    "        return normalized * self.target_range + self.target_min\n",
    "\n",
    "\n",
    "class BaseCompressor(nn.Module):\n",
    "    \"\"\"Base compression network: 4 -> 64 -> 64 -> 32 -> 4\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BaseCompressor, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(4, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 4)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class LargeCompressor(nn.Module):\n",
    "    \"\"\"Large compression network: 4 -> 128 -> 128 -> 64 -> 4\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LargeCompressor, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(4, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 4)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "def compute_psnr_ssim(predictions, targets, device):\n",
    "    \"\"\"Compute PSNR and SSIM for regression data using per-point comparison (kernel_size=1).\"\"\"\n",
    "    predictions = predictions.to(device)\n",
    "    targets = targets.to(device)\n",
    "\n",
    "    psnr_metric = PeakSignalNoiseRatio().to(device)\n",
    "    psnr_metric.update(predictions, targets)\n",
    "    psnr = psnr_metric.compute().item()\n",
    "\n",
    "    pred_ssim = predictions.view(-1, 1, 1, predictions.shape[1])\n",
    "    target_ssim = targets.view(-1, 1, 1, targets.shape[1])\n",
    "    pred_ssim = pred_ssim.permute(1, 2, 0, 3)\n",
    "    target_ssim = target_ssim.permute(1, 2, 0, 3)\n",
    "\n",
    "    ssim_metric = StructuralSimilarityIndexMeasure(\n",
    "        gaussian_kernel=False, kernel_size=1\n",
    "    ).to(device)\n",
    "    ssim_metric.update(pred_ssim, target_ssim)\n",
    "    ssim = ssim_metric.compute().item()\n",
    "\n",
    "    return psnr, ssim\n",
    "\n",
    "\n",
    "def compute_relative_error(predictions, targets):\n",
    "    \"\"\"Compute relative L2 norm error as a percentage.\"\"\"\n",
    "    target_norm = torch.norm(targets)\n",
    "    error = torch.norm(predictions - targets)\n",
    "    return (error / target_norm * 100).item()\n",
    "\n",
    "\n",
    "def train_online(model, dataset, device, epochs_per_window, model_name, output_dir, num_windows=20):\n",
    "    \"\"\"Train a compression model using online streaming with temporal windows.\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    all_metrics = {\n",
    "        'window': [],\n",
    "        'loss': [],\n",
    "        'psnr': [],\n",
    "        'ssim': [],\n",
    "        'relative_error': [],\n",
    "        'time_per_window': []\n",
    "    }\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"\\n[Train] Model: {model_name}\")\n",
    "    print(f\"[Train] Samples: {len(dataset):,} | Windows: {num_windows} | Epochs/Window: {epochs_per_window}\")\n",
    "    print(f\"[Train] Device: {device} | Parameters: {total_params:,} | Size: {total_params * 4 / 1024:.2f} KB\")\n",
    "\n",
    "    coords_denorm = dataset.denormalize_input(dataset.inputs)\n",
    "    unique_times = np.unique(coords_denorm[:, 3])\n",
    "    times_per_window = len(unique_times) // num_windows\n",
    "    print(f\"[Train] Unique timesteps: {len(unique_times)} | Timesteps/Window: {times_per_window}\\n\")\n",
    "\n",
    "    for window_idx in range(num_windows):\n",
    "        window_start_time = time.time()\n",
    "\n",
    "        start_idx = window_idx * times_per_window\n",
    "        end_idx = start_idx + times_per_window if window_idx < num_windows - 1 else len(unique_times)\n",
    "        window_times = unique_times[start_idx:end_idx]\n",
    "\n",
    "        time_mask = np.isin(coords_denorm[:, 3], window_times)\n",
    "        window_inputs = torch.from_numpy(dataset.inputs[time_mask]).to(device)\n",
    "        window_targets = torch.from_numpy(dataset.targets[time_mask]).to(device)\n",
    "\n",
    "        print(f\"  Window {window_idx+1:>2}/{num_windows}: {len(window_inputs):,} samples, \"\n",
    "              f\"t=[{window_times[0]:.4f}, {window_times[-1]:.4f}]\")\n",
    "\n",
    "        for epoch in range(epochs_per_window):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(window_inputs)\n",
    "            loss = criterion(outputs, window_targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions = model(window_inputs)\n",
    "\n",
    "        loss_val = criterion(predictions, window_targets).item()\n",
    "        psnr, ssim = compute_psnr_ssim(predictions, window_targets, device)\n",
    "        rel_error = compute_relative_error(predictions, window_targets)\n",
    "\n",
    "        window_time = time.time() - window_start_time\n",
    "\n",
    "        all_metrics['window'].append(window_idx + 1)\n",
    "        all_metrics['loss'].append(loss_val)\n",
    "        all_metrics['psnr'].append(psnr)\n",
    "        all_metrics['ssim'].append(ssim)\n",
    "        all_metrics['relative_error'].append(rel_error)\n",
    "        all_metrics['time_per_window'].append(window_time)\n",
    "\n",
    "        print(f\"           Loss={loss_val:.6f}, PSNR={psnr:.2f} dB, SSIM={ssim:.4f}, \"\n",
    "              f\"Rel. Error={rel_error:.2f}%, Time={window_time:.2f}s\")\n",
    "\n",
    "        window_dir = os.path.join(output_dir, f'window_{window_idx+1:02d}')\n",
    "        os.makedirs(window_dir, exist_ok=True)\n",
    "        torch.save(model.state_dict(),\n",
    "                   os.path.join(window_dir, f'{model_name}_window_{window_idx+1:02d}.pth'))\n",
    "\n",
    "    final_model_path = os.path.join(output_dir, f'{model_name}_online_final.pth')\n",
    "    torch.save(model.state_dict(), final_model_path)\n",
    "    print(f\"\\n[Train] Final model saved: {final_model_path}\")\n",
    "\n",
    "    norm_params = {\n",
    "        'input_min': dataset.input_min.tolist(),\n",
    "        'input_max': dataset.input_max.tolist(),\n",
    "        'input_range': dataset.input_range.tolist(),\n",
    "        'target_min': dataset.target_min.tolist(),\n",
    "        'target_max': dataset.target_max.tolist(),\n",
    "        'target_range': dataset.target_range.tolist()\n",
    "    }\n",
    "    norm_path = os.path.join(output_dir, f'{model_name}_normalization.json')\n",
    "    with open(norm_path, 'w') as f:\n",
    "        json.dump(norm_params, f, indent=2)\n",
    "    print(f\"[Train] Normalization parameters saved: {norm_path}\")\n",
    "\n",
    "    summary = {\n",
    "        'model_name': model_name,\n",
    "        'total_windows': num_windows,\n",
    "        'epochs_per_window': epochs_per_window,\n",
    "        'total_epochs': num_windows * epochs_per_window,\n",
    "        'final_loss': all_metrics['loss'][-1],\n",
    "        'final_psnr': all_metrics['psnr'][-1],\n",
    "        'final_ssim': all_metrics['ssim'][-1],\n",
    "        'final_relative_error': all_metrics['relative_error'][-1],\n",
    "        'total_training_time': sum(all_metrics['time_per_window']),\n",
    "        'avg_time_per_window': np.mean(all_metrics['time_per_window'])\n",
    "    }\n",
    "    summary_path = os.path.join(output_dir, 'online_training_summary.json')\n",
    "    with open(summary_path, 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "    print(f\"\\n[Train] Online training completed for {model_name}\")\n",
    "    print(f\"  Total Windows:        {num_windows}\")\n",
    "    print(f\"  Total Epochs:         {num_windows * epochs_per_window}\")\n",
    "    print(f\"  Final Loss:           {all_metrics['loss'][-1]:.6f}\")\n",
    "    print(f\"  Final PSNR:           {all_metrics['psnr'][-1]:.2f} dB\")\n",
    "    print(f\"  Final SSIM:           {all_metrics['ssim'][-1]:.4f}\")\n",
    "    print(f\"  Final Relative Error: {all_metrics['relative_error'][-1]:.2f}%\")\n",
    "    print(f\"  Total Time:           {sum(all_metrics['time_per_window']):.2f}s\\n\")\n",
    "\n",
    "    return all_metrics\n",
    "\n",
    "\n",
    "def export_metrics_csv(metrics, output_path):\n",
    "    \"\"\"Export training metrics history to CSV.\"\"\"\n",
    "    df = pd.DataFrame(metrics)\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"[Export] Metrics saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = \"/kaggle/input/ml-test-loader-original-data-csv/ML_test_loader_original_data.csv\"\n",
    "EPOCHS_PER_WINDOW = 100\n",
    "NUM_WINDOWS = 20\n",
    "TIMESTEP = 0.0396\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"[Config] Device: {device}\")\n",
    "\n",
    "dataset = FlowFieldDataset(DATA_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Base Model (64-64-32) — Online Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_OUTPUT_DIR = \"/kaggle/working/results/base_model_online\"\n",
    "\n",
    "base_model = BaseCompressor().to(device)\n",
    "\n",
    "base_metrics = train_online(\n",
    "    model=base_model,\n",
    "    dataset=dataset,\n",
    "    device=device,\n",
    "    epochs_per_window=EPOCHS_PER_WINDOW,\n",
    "    model_name='base_model',\n",
    "    output_dir=BASE_OUTPUT_DIR,\n",
    "    num_windows=NUM_WINDOWS\n",
    ")\n",
    "\n",
    "export_metrics_csv(base_metrics, f\"{BASE_OUTPUT_DIR}/base_model_online_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "axes[0, 0].plot(base_metrics['window'], base_metrics['loss'], 'b-o', linewidth=2, markersize=4)\n",
    "axes[0, 0].set_xlabel('Window')\n",
    "axes[0, 0].set_ylabel('MSE Loss')\n",
    "axes[0, 0].set_title('Loss per Window (Normalized)')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[0, 1].plot(base_metrics['window'], base_metrics['psnr'], 'g-o', linewidth=2, markersize=4)\n",
    "axes[0, 1].set_xlabel('Window')\n",
    "axes[0, 1].set_ylabel('PSNR (dB)')\n",
    "axes[0, 1].set_title('Peak Signal-to-Noise Ratio')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 0].plot(base_metrics['window'], base_metrics['ssim'], 'purple', linewidth=2, marker='o', markersize=4)\n",
    "axes[1, 0].set_xlabel('Window')\n",
    "axes[1, 0].set_ylabel('SSIM')\n",
    "axes[1, 0].set_title('Structural Similarity Index')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].set_ylim([0, 1.05])\n",
    "\n",
    "axes[1, 1].plot(base_metrics['window'], base_metrics['relative_error'], 'r-o', linewidth=2, markersize=4)\n",
    "axes[1, 1].set_xlabel('Window')\n",
    "axes[1, 1].set_ylabel('Relative Error (%)')\n",
    "axes[1, 1].set_title('Reconstruction Error')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(f'Base Model (64-64-32) — Online Training — {NUM_WINDOWS} Windows',\n",
    "             fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{BASE_OUTPUT_DIR}/base_model_online_progress.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Base Model — Evaluation & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_VIZ_DIR = \"/kaggle/working/results/base_model_online_viz\"\n",
    "os.makedirs(BASE_VIZ_DIR, exist_ok=True)\n",
    "\n",
    "base_model.load_state_dict(torch.load(f\"{BASE_OUTPUT_DIR}/base_model_online_final.pth\", map_location=device))\n",
    "base_model.eval()\n",
    "\n",
    "print(f\"[Eval] Base model: {sum(p.numel() for p in base_model.parameters()):,} parameters\")\n",
    "\n",
    "all_inputs = torch.from_numpy(dataset.inputs).to(device)\n",
    "with torch.no_grad():\n",
    "    base_predictions = base_model(all_inputs).cpu()\n",
    "\n",
    "all_targets = torch.from_numpy(dataset.targets)\n",
    "\n",
    "base_psnr, base_ssim = compute_psnr_ssim(base_predictions, all_targets, device)\n",
    "print(f\"[Eval] PSNR: {base_psnr:.2f} dB | SSIM: {base_ssim:.4f}\")\n",
    "\n",
    "base_pred_denorm = dataset.denormalize_target(base_predictions.numpy())\n",
    "targets_denorm = dataset.denormalize_target(all_targets.numpy())\n",
    "coords_denorm = dataset.denormalize_input(dataset.inputs)\n",
    "\n",
    "timestep_mask = np.abs(coords_denorm[:, 3] - TIMESTEP) < 1e-6\n",
    "x = coords_denorm[timestep_mask, 0]\n",
    "y = coords_denorm[timestep_mask, 1]\n",
    "base_pred_t = base_pred_denorm[timestep_mask]\n",
    "target_t = targets_denorm[timestep_mask]\n",
    "base_errors_t = np.abs(target_t - base_pred_t)\n",
    "\n",
    "print(f\"[Eval] Visualizing {len(x):,} points at timestep {TIMESTEP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['Vx', 'Vy', 'Pressure', 'TKE']\n",
    "feature_indices = [0, 1, 2, 3]\n",
    "\n",
    "fig, axes = plt.subplots(4, 3, figsize=(18, 20))\n",
    "\n",
    "for row, (idx, name) in enumerate(zip(feature_indices, feature_names)):\n",
    "    original = target_t[:, idx]\n",
    "    predicted = base_pred_t[:, idx]\n",
    "    error = base_errors_t[:, idx]\n",
    "\n",
    "    sc1 = axes[row, 0].scatter(x, y, c=original, cmap='jet', s=0.5, alpha=0.8)\n",
    "    axes[row, 0].set_title(f'Original: {name}')\n",
    "    axes[row, 0].set_aspect('equal')\n",
    "    axes[row, 0].grid(True, alpha=0.3)\n",
    "    plt.colorbar(sc1, ax=axes[row, 0])\n",
    "\n",
    "    sc2 = axes[row, 1].scatter(x, y, c=predicted, cmap='jet', s=0.5, alpha=0.8)\n",
    "    axes[row, 1].set_title(f'Predicted: {name}')\n",
    "    axes[row, 1].set_aspect('equal')\n",
    "    axes[row, 1].grid(True, alpha=0.3)\n",
    "    plt.colorbar(sc2, ax=axes[row, 1])\n",
    "\n",
    "    sc3 = axes[row, 2].scatter(x, y, c=error, cmap='hot', s=0.5, alpha=0.8)\n",
    "    axes[row, 2].set_title(f'Absolute Error: {name}')\n",
    "    axes[row, 2].set_aspect('equal')\n",
    "    axes[row, 2].grid(True, alpha=0.3)\n",
    "    plt.colorbar(sc3, ax=axes[row, 2])\n",
    "\n",
    "plt.suptitle(f'Base Model (64-64-32) Online — PSNR: {base_psnr:.2f} dB | Timestep: {TIMESTEP}',\n",
    "             fontsize=14, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{BASE_VIZ_DIR}/base_online_visualization.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "base_eval_metrics = {\n",
    "    'model': 'base_model_online_final.pth',\n",
    "    'architecture': '4-64-64-32-4',\n",
    "    'training_mode': 'online_streaming',\n",
    "    'parameters': sum(p.numel() for p in base_model.parameters()),\n",
    "    'psnr_db': float(base_psnr),\n",
    "    'ssim': float(base_ssim)\n",
    "}\n",
    "\n",
    "with open(f\"{BASE_VIZ_DIR}/evaluation_metrics.json\", 'w') as f:\n",
    "    json.dump(base_eval_metrics, f, indent=2)\n",
    "\n",
    "print(\"[Eval] Base model evaluation completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Large Model (128-128-64) — Online Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LARGE_OUTPUT_DIR = \"/kaggle/working/results/large_model_online\"\n",
    "\n",
    "large_model = LargeCompressor().to(device)\n",
    "\n",
    "large_metrics = train_online(\n",
    "    model=large_model,\n",
    "    dataset=dataset,\n",
    "    device=device,\n",
    "    epochs_per_window=EPOCHS_PER_WINDOW,\n",
    "    model_name='large_model',\n",
    "    output_dir=LARGE_OUTPUT_DIR,\n",
    "    num_windows=NUM_WINDOWS\n",
    ")\n",
    "\n",
    "export_metrics_csv(large_metrics, f\"{LARGE_OUTPUT_DIR}/large_model_online_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "axes[0, 0].plot(large_metrics['window'], large_metrics['loss'], 'b-o', linewidth=2, markersize=4)\n",
    "axes[0, 0].set_xlabel('Window')\n",
    "axes[0, 0].set_ylabel('MSE Loss')\n",
    "axes[0, 0].set_title('Loss per Window (Normalized)')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[0, 1].plot(large_metrics['window'], large_metrics['psnr'], 'g-o', linewidth=2, markersize=4)\n",
    "axes[0, 1].set_xlabel('Window')\n",
    "axes[0, 1].set_ylabel('PSNR (dB)')\n",
    "axes[0, 1].set_title('Peak Signal-to-Noise Ratio')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 0].plot(large_metrics['window'], large_metrics['ssim'], 'purple', linewidth=2, marker='o', markersize=4)\n",
    "axes[1, 0].set_xlabel('Window')\n",
    "axes[1, 0].set_ylabel('SSIM')\n",
    "axes[1, 0].set_title('Structural Similarity Index')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].set_ylim([0, 1.05])\n",
    "\n",
    "axes[1, 1].plot(large_metrics['window'], large_metrics['relative_error'], 'r-o', linewidth=2, markersize=4)\n",
    "axes[1, 1].set_xlabel('Window')\n",
    "axes[1, 1].set_ylabel('Relative Error (%)')\n",
    "axes[1, 1].set_title('Reconstruction Error')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(f'Large Model (128-128-64) — Online Training — {NUM_WINDOWS} Windows',\n",
    "             fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{LARGE_OUTPUT_DIR}/large_model_online_progress.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Large Model — Evaluation & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LARGE_VIZ_DIR = \"/kaggle/working/results/large_model_online_viz\"\n",
    "os.makedirs(LARGE_VIZ_DIR, exist_ok=True)\n",
    "\n",
    "large_model.load_state_dict(torch.load(f\"{LARGE_OUTPUT_DIR}/large_model_online_final.pth\", map_location=device))\n",
    "large_model.eval()\n",
    "\n",
    "print(f\"[Eval] Large model: {sum(p.numel() for p in large_model.parameters()):,} parameters\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    large_predictions = large_model(all_inputs).cpu()\n",
    "\n",
    "large_psnr, large_ssim = compute_psnr_ssim(large_predictions, all_targets, device)\n",
    "print(f\"[Eval] PSNR: {large_psnr:.2f} dB | SSIM: {large_ssim:.4f}\")\n",
    "\n",
    "large_pred_denorm = dataset.denormalize_target(large_predictions.numpy())\n",
    "\n",
    "large_pred_t = large_pred_denorm[timestep_mask]\n",
    "large_errors_t = np.abs(target_t - large_pred_t)\n",
    "\n",
    "print(f\"[Eval] Visualizing {len(x):,} points at timestep {TIMESTEP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 3, figsize=(18, 20))\n",
    "\n",
    "for row, (idx, name) in enumerate(zip(feature_indices, feature_names)):\n",
    "    original = target_t[:, idx]\n",
    "    predicted = large_pred_t[:, idx]\n",
    "    error = large_errors_t[:, idx]\n",
    "\n",
    "    sc1 = axes[row, 0].scatter(x, y, c=original, cmap='jet', s=0.5, alpha=0.8)\n",
    "    axes[row, 0].set_title(f'Original: {name}')\n",
    "    axes[row, 0].set_aspect('equal')\n",
    "    axes[row, 0].grid(True, alpha=0.3)\n",
    "    plt.colorbar(sc1, ax=axes[row, 0])\n",
    "\n",
    "    sc2 = axes[row, 1].scatter(x, y, c=predicted, cmap='jet', s=0.5, alpha=0.8)\n",
    "    axes[row, 1].set_title(f'Predicted: {name}')\n",
    "    axes[row, 1].set_aspect('equal')\n",
    "    axes[row, 1].grid(True, alpha=0.3)\n",
    "    plt.colorbar(sc2, ax=axes[row, 1])\n",
    "\n",
    "    sc3 = axes[row, 2].scatter(x, y, c=error, cmap='hot', s=0.5, alpha=0.8)\n",
    "    axes[row, 2].set_title(f'Absolute Error: {name}')\n",
    "    axes[row, 2].set_aspect('equal')\n",
    "    axes[row, 2].grid(True, alpha=0.3)\n",
    "    plt.colorbar(sc3, ax=axes[row, 2])\n",
    "\n",
    "plt.suptitle(f'Large Model (128-128-64) Online — PSNR: {large_psnr:.2f} dB | Timestep: {TIMESTEP}',\n",
    "             fontsize=14, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{LARGE_VIZ_DIR}/large_online_visualization.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "large_eval_metrics = {\n",
    "    'model': 'large_model_online_final.pth',\n",
    "    'architecture': '4-128-128-64-4',\n",
    "    'training_mode': 'online_streaming',\n",
    "    'parameters': sum(p.numel() for p in large_model.parameters()),\n",
    "    'psnr_db': float(large_psnr),\n",
    "    'ssim': float(large_ssim)\n",
    "}\n",
    "\n",
    "with open(f\"{LARGE_VIZ_DIR}/evaluation_metrics.json\", 'w') as f:\n",
    "    json.dump(large_eval_metrics, f, indent=2)\n",
    "\n",
    "print(\"[Eval] Large model evaluation completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 65)\n",
    "print(\"ONLINE TRAINING — MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\" * 65)\n",
    "print(f\"{'Metric':<25} {'Base (64-64-32)':>18} {'Large (128-128-64)':>20}\")\n",
    "print(\"-\" * 65)\n",
    "print(f\"{'Parameters':<25} {sum(p.numel() for p in base_model.parameters()):>18,} {sum(p.numel() for p in large_model.parameters()):>20,}\")\n",
    "print(f\"{'Model Size (KB)':<25} {sum(p.numel() for p in base_model.parameters()) * 4 / 1024:>18.2f} {sum(p.numel() for p in large_model.parameters()) * 4 / 1024:>20.2f}\")\n",
    "print(f\"{'Windows':<25} {NUM_WINDOWS:>18} {NUM_WINDOWS:>20}\")\n",
    "print(f\"{'Epochs/Window':<25} {EPOCHS_PER_WINDOW:>18} {EPOCHS_PER_WINDOW:>20}\")\n",
    "print(f\"{'Total Epochs':<25} {NUM_WINDOWS * EPOCHS_PER_WINDOW:>18} {NUM_WINDOWS * EPOCHS_PER_WINDOW:>20}\")\n",
    "print(f\"{'Final Window Loss':<25} {base_metrics['loss'][-1]:>18.6f} {large_metrics['loss'][-1]:>20.6f}\")\n",
    "print(f\"{'Final Window PSNR (dB)':<25} {base_metrics['psnr'][-1]:>18.2f} {large_metrics['psnr'][-1]:>20.2f}\")\n",
    "print(f\"{'Final Window SSIM':<25} {base_metrics['ssim'][-1]:>18.4f} {large_metrics['ssim'][-1]:>20.4f}\")\n",
    "print(f\"{'Final Rel. Error (%)':<25} {base_metrics['relative_error'][-1]:>18.2f} {large_metrics['relative_error'][-1]:>20.2f}\")\n",
    "print(f\"{'Eval PSNR (dB)':<25} {base_psnr:>18.2f} {large_psnr:>20.2f}\")\n",
    "print(f\"{'Eval SSIM':<25} {base_ssim:>18.4f} {large_ssim:>20.4f}\")\n",
    "print(\"=\" * 65)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}